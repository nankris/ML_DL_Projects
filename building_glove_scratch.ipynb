{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbc624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nandigam.Krishna\\anaconda3\\envs\\py_310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# If needed:\n",
    "# pip install torch tqdm\n",
    "\n",
    "import re, math, collections, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb6f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3995274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"king queen man woman prince princess royal palace throne crown\",\n",
    "    \"the quick brown fox jumps over the lazy dog\",\n",
    "    \"paris is the capital of france and rome is the capital of italy\",\n",
    "    \"ice is solid at low temperature but steam is gas at high temperature\",\n",
    "    \"deep learning uses neural networks and gradient descent optimization\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36b16192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 43\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "tokens = [tokenize(doc) for doc in corpus]\n",
    "min_count = 1\n",
    "\n",
    "freq = collections.Counter(w for doc in tokens for w in doc)\n",
    "vocab = [w for w,c in freq.items() if c >= min_count]\n",
    "vocab.sort()\n",
    "stoi = {w:i for i,w in enumerate(vocab)}\n",
    "itos = {i:w for w,i in stoi.items()}\n",
    "V = len(vocab)\n",
    "print(\"Vocab size:\", V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "470a0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d7cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3301c1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,\n",
       " array([[18, 32, 1.0],\n",
       "        [18, 22, 0.5],\n",
       "        [18, 42, 0.3333333333333333],\n",
       "        [18, 30, 0.25],\n",
       "        [18, 31, 0.2]], dtype=object))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win = 5\n",
    "cooc = collections.defaultdict(float)\n",
    "\n",
    "for doc in tokens:\n",
    "    for i, wi in enumerate(doc):\n",
    "        wi_idx = stoi.get(wi)\n",
    "        if wi_idx is None: \n",
    "            continue\n",
    "        start = max(0, i - win)\n",
    "        end   = min(len(doc), i + win + 1)\n",
    "        for j in range(start, end):\n",
    "            if i == j: \n",
    "                continue\n",
    "            wj = doc[j]\n",
    "            wj_idx = stoi.get(wj)\n",
    "            if wj_idx is None: \n",
    "                continue\n",
    "            dist = abs(j - i)\n",
    "            cooc[(wi_idx, wj_idx)] += 1.0 / dist\n",
    "\n",
    "pairs = np.array([(i,j,x) for (i,j),x in cooc.items() if x>0.0], dtype=object)\n",
    "len(pairs), pairs[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11087497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoocDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.i = np.array([p[0] for p in pairs], dtype=np.int64)\n",
    "        self.j = np.array([p[1] for p in pairs], dtype=np.int64)\n",
    "        self.x = np.array([p[2] for p in pairs], dtype=np.float32)\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.i[idx], self.j[idx], self.x[idx])\n",
    "\n",
    "batch_size = 1024\n",
    "ds = CoocDataset(pairs)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734ae6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    def __init__(self, vocab_size, dim=50):\n",
    "        super().__init__()\n",
    "        self.W  = nn.Embedding(vocab_size, dim)       # word\n",
    "        self.C  = nn.Embedding(vocab_size, dim)       # context\n",
    "        self.b  = nn.Embedding(vocab_size, 1)         # word bias\n",
    "        self.bt = nn.Embedding(vocab_size, 1)         # context bias\n",
    "        # init\n",
    "        nn.init.xavier_uniform_(self.W.weight)\n",
    "        nn.init.xavier_uniform_(self.C.weight)\n",
    "        nn.init.zeros_(self.b.weight)\n",
    "        nn.init.zeros_(self.bt.weight)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, i, j):\n",
    "        wi = self.W(i)        # (B, d)\n",
    "        wj = self.C(j)        # (B, d)\n",
    "        bi = self.b(i).squeeze(-1)   # (B,)\n",
    "        bj = self.bt(j).squeeze(-1)  # (B,)\n",
    "        dot = (wi * wj).sum(dim=1)   # (B,)\n",
    "        return dot + bi + bj          # predicted log(X_ij)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce22a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams (paper defaults work well)\n",
    "dim = 50\n",
    "x_max = 100.0\n",
    "alpha = 0.75\n",
    "epochs = 30\n",
    "lr = 0.05\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GloVe(V, dim=dim).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddeb58db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.0103\n",
      "Epoch 02 | Loss: 0.0049\n",
      "Epoch 03 | Loss: 0.0019\n",
      "Epoch 04 | Loss: 0.0010\n",
      "Epoch 05 | Loss: 0.0012\n",
      "Epoch 06 | Loss: 0.0014\n",
      "Epoch 07 | Loss: 0.0012\n",
      "Epoch 08 | Loss: 0.0007\n",
      "Epoch 09 | Loss: 0.0005\n",
      "Epoch 10 | Loss: 0.0006\n",
      "Epoch 11 | Loss: 0.0007\n",
      "Epoch 12 | Loss: 0.0007\n",
      "Epoch 13 | Loss: 0.0006\n",
      "Epoch 14 | Loss: 0.0004\n",
      "Epoch 15 | Loss: 0.0003\n",
      "Epoch 16 | Loss: 0.0003\n",
      "Epoch 17 | Loss: 0.0003\n",
      "Epoch 18 | Loss: 0.0003\n",
      "Epoch 19 | Loss: 0.0002\n",
      "Epoch 20 | Loss: 0.0002\n",
      "Epoch 21 | Loss: 0.0002\n",
      "Epoch 22 | Loss: 0.0002\n",
      "Epoch 23 | Loss: 0.0002\n",
      "Epoch 24 | Loss: 0.0001\n",
      "Epoch 25 | Loss: 0.0001\n",
      "Epoch 26 | Loss: 0.0001\n",
      "Epoch 27 | Loss: 0.0001\n",
      "Epoch 28 | Loss: 0.0001\n",
      "Epoch 29 | Loss: 0.0001\n",
      "Epoch 30 | Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "def weight_fn(x_ij):\n",
    "    # f(x) = (x/x_max)^alpha  if x < x_max else 1\n",
    "    wx = (x_ij / x_max) ** alpha\n",
    "    return torch.where(x_ij < x_max, wx, torch.ones_like(x_ij))\n",
    "\n",
    "model.train()\n",
    "for ep in range(1, epochs+1):\n",
    "    total_loss = 0.0\n",
    "    for i, j, x in dl:\n",
    "        i = i.to(device)\n",
    "        j = j.to(device)\n",
    "        x = x.to(device)\n",
    "\n",
    "        pred = model(i, j)\n",
    "        w = weight_fn(x)\n",
    "        loss = (w * (pred - torch.log(x))**2).mean()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * len(x)\n",
    "\n",
    "    print(f\"Epoch {ep:02d} | Loss: {total_loss/len(ds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d847f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings(model):\n",
    "    emb = model.W.weight + model.C.weight     # v_i = w_i + wÌƒ_i\n",
    "    return emb.cpu().numpy()\n",
    "\n",
    "E = get_embeddings(model)  # shape: (V, dim)\n",
    "\n",
    "# Cosine similarity utilities\n",
    "def vec(w):\n",
    "    return E[stoi[w]]\n",
    "\n",
    "def most_similar(word, topn=5):\n",
    "    v = vec(word)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    M = E / np.linalg.norm(E, axis=1, keepdims=True)\n",
    "    sims = M @ v\n",
    "    ranks = np.argsort(-sims)\n",
    "    out = []\n",
    "    for idx in ranks:\n",
    "        w = itos[idx]\n",
    "        if w == word: \n",
    "            continue\n",
    "        out.append((w, float(sims[idx])))\n",
    "        if len(out) >= topn:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def analogy(a, b, c, topn=5):\n",
    "    # a:b :: c:?\n",
    "    v = vec(b) - vec(a) + vec(c)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    M = E / np.linalg.norm(E, axis=1, keepdims=True)\n",
    "    sims = M @ v\n",
    "    ranks = np.argsort(-sims)\n",
    "    out = []\n",
    "    ban = {a,b,c}\n",
    "    for idx in ranks:\n",
    "        w = itos[idx]\n",
    "        if w in ban: \n",
    "            continue\n",
    "        out.append((w, float(sims[idx])))\n",
    "        if len(out) >= topn:\n",
    "            break\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6949fa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to 'king': [('queen', 0.7101271152496338), ('crown', 0.6386337280273438), ('throne', 0.482085257768631), ('dog', 0.4398803114891052), ('lazy', 0.36637669801712036)]\n",
      "Analogy king:man :: ? : woman -> [('palace', 0.39574524760246277), ('lazy', 0.3455282151699066), ('queen', 0.2928714454174042), ('royal', 0.2756752371788025), ('crown', 0.26887965202331543)]\n",
      "Similar to 'paris': [('rome', 0.5738002061843872), ('over', 0.3151131570339203), ('low', 0.2945200204849243), ('descent', 0.25710663199424744), ('at', 0.19899845123291016)]\n",
      "Similar to 'temperature': [('but', 0.5507892370223999), ('low', 0.5312858819961548), ('steam', 0.4997710883617401), ('at', 0.31528133153915405), ('the', 0.28273504972457886)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Similar to 'king':\", most_similar(\"king\"))\n",
    "print(\"Analogy king:man :: ? : woman ->\", analogy(\"man\", \"king\", \"woman\"))\n",
    "print(\"Similar to 'paris':\", most_similar(\"paris\"))\n",
    "print(\"Similar to 'temperature':\", most_similar(\"temperature\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7593a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to mini_glove.txt\n"
     ]
    }
   ],
   "source": [
    "out_path = \"mini_glove.txt\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"{V} {dim}\\n\")\n",
    "    for i in range(V):\n",
    "        w = itos[i]\n",
    "        vec_str = \" \".join(f\"{x:.6f}\" for x in E[i])\n",
    "        f.write(f\"{w} {vec_str}\\n\")\n",
    "print(\"Saved to\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1cf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937e437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
